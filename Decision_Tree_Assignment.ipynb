{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fdbc868e",
      "metadata": {
        "id": "fdbc868e"
      },
      "source": [
        "\n",
        "\n",
        "## **Decision Tree | Assignment**\n",
        "---\n",
        "\n",
        "## **Question 1:**  \n",
        "What is a Decision Tree, and how does it work in the context of classification?\n",
        "\n",
        "### **Answer:**\n",
        "A **Decision Tree** is a supervised machine learning algorithm used for both **classification** and **regression** tasks.  \n",
        "It works by splitting the dataset into branches based on feature values, forming a tree-like structure where each internal node represents a **decision rule**, each branch represents an **outcome**, and each leaf node represents a **class label** (in classification) or a **value** (in regression).\n",
        "\n",
        "In classification:\n",
        "- The algorithm selects the feature that provides the **best split** of the data (using impurity measures such as Gini or Entropy).\n",
        "- It continues splitting recursively until a stopping criterion (like maximum depth or minimum samples) is met.\n",
        "- The final prediction for a sample is made based on the **majority class** in the leaf node it falls into.\n",
        "\n",
        "Decision Trees mimic human decision-making, making them easy to interpret and visualize.\n",
        "\n",
        "---\n",
        "\n",
        "## **Question 2:**  \n",
        "Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
        "\n",
        "### **Answer:**\n",
        "**Gini Impurity** and **Entropy** are measures used to evaluate the \"purity\" of a dataset at a node.\n",
        "\n",
        "- **Gini Impurity:**\n",
        "  \\[\n",
        "  Gini = 1 - \\sum (p_i)^2\n",
        "  \\]\n",
        "  where \\( p_i \\) is the probability of each class.\n",
        "  - It measures how often a randomly chosen element would be incorrectly labeled if it were randomly labeled according to the distribution of labels in the node.\n",
        "  - A **Gini value of 0** means the node is pure (contains only one class).\n",
        "\n",
        "- **Entropy:**\n",
        "  \\[\n",
        "  Entropy = -\\sum p_i \\log_2(p_i)\n",
        "  \\]\n",
        "  - It measures the amount of disorder or randomness in the dataset.\n",
        "  - A higher entropy value means the data is more impure.\n",
        "\n",
        "**Impact on Splits:**  \n",
        "Both metrics aim to find splits that **reduce impurity** the most. The feature and threshold producing the **highest decrease in impurity** (called *Information Gain*) are selected for splitting.\n",
        "\n",
        "---\n",
        "\n",
        "## **Question 3:**  \n",
        "What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
        "\n",
        "### **Answer:**\n",
        "- **Pre-Pruning:**  \n",
        "  Stops the tree growth early before it becomes too complex.  \n",
        "  Example: Limiting the `max_depth` or `min_samples_split`.  \n",
        "  - **Advantage:** Saves computation time and prevents overfitting early.\n",
        "\n",
        "- **Post-Pruning:**  \n",
        "  Grows the full tree first, then removes branches that do not improve accuracy on validation data.  \n",
        "  Example: Cost complexity pruning (`ccp_alpha` in sklearn).  \n",
        "  - **Advantage:** Produces a more optimized tree after evaluating model performance.\n",
        "\n",
        "---\n",
        "\n",
        "## **Question 4:**  \n",
        "What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
        "\n",
        "### **Answer:**\n",
        "**Information Gain (IG)** measures the reduction in impurity (entropy or Gini) after a dataset is split on a particular feature.\n",
        "\n",
        "\\[\n",
        "IG = Entropy(parent) - \\sum \\frac{n_{child}}{n_{total}} \\times Entropy(child)\n",
        "\\]\n",
        "\n",
        "- A higher **Information Gain** means the feature provides a better split.\n",
        "- It helps the decision tree algorithm **choose the most informative feature** at each step, ensuring efficient and accurate classification.\n",
        "\n",
        "Hence, Information Gain guides the tree-building process by identifying splits that **maximize purity and minimize uncertainty**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Question 5:**  \n",
        "What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n",
        "\n",
        "### **Answer:**\n",
        "\n",
        "**Applications:**\n",
        "- Medical diagnosis (disease prediction)\n",
        "- Financial risk analysis and loan approval\n",
        "- Customer segmentation and churn prediction\n",
        "- Fraud detection\n",
        "- Manufacturing defect classification\n",
        "\n",
        "**Advantages:**\n",
        "- Easy to understand and visualize\n",
        "- Works with both numerical and categorical data\n",
        "- Requires little data preprocessing\n",
        "- Handles non-linear relationships\n",
        "\n",
        "**Limitations:**\n",
        "- Prone to overfitting (especially deep trees)\n",
        "- Small data changes can lead to a completely different tree\n",
        "- May be biased toward features with more levels\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 6:**   \n",
        "\n",
        "  Write a Python program to: \\\n",
        "● Load the Iris Dataset \\\n",
        "● Train a Decision Tree Classifier using the Gini criterion \\\n",
        "● Print the model’s accuracy and feature importances"
      ],
      "metadata": {
        "id": "48W9JJjvD81O"
      },
      "id": "48W9JJjvD81O"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bcef75b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcef75b7",
        "outputId": "8e1d9202-6083-4d0c-e145-2c05deceeb98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n",
            "Feature Importances: [0.         0.01911002 0.89326355 0.08762643]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train model\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "print(\"Feature Importances:\", clf.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 7:**  \n",
        " Write a Python program to: \\\n",
        "● Load the Iris Dataset \\\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree."
      ],
      "metadata": {
        "id": "ODL7HXMjESIp"
      },
      "id": "ODL7HXMjESIp"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4ac8fb26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ac8fb26",
        "outputId": "43f7fbb5-2241-47dd-b49d-2efc095cdd36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Full Tree): 1.0\n",
            "Accuracy (Max Depth = 3): 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Full tree\n",
        "full_tree = DecisionTreeClassifier(random_state=42)\n",
        "full_tree.fit(X_train, y_train)\n",
        "full_pred = full_tree.predict(X_test)\n",
        "full_acc = accuracy_score(y_test, full_pred)\n",
        "\n",
        "# Limited depth tree\n",
        "limited_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "limited_tree.fit(X_train, y_train)\n",
        "limited_pred = limited_tree.predict(X_test)\n",
        "limited_acc = accuracy_score(y_test, limited_pred)\n",
        "\n",
        "print(\"Accuracy (Full Tree):\", full_acc)\n",
        "print(\"Accuracy (Max Depth = 3):\", limited_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f943ac8",
      "metadata": {
        "id": "8f943ac8"
      },
      "source": [
        "\n",
        "## **Question 8:**\n",
        "\n",
        " Write a Python program to: \\\n",
        "● Load the Boston Housing Dataset \\\n",
        "● Train a Decision Tree Regressor \\\n",
        "● Print the Mean Squared Error (MSE) and feature importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6fe6d69d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fe6d69d",
        "outputId": "0617665c-82ad-4fab-b359-53cd094df1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.5280096503174904\n",
            "Feature Importances: [0.52345628 0.05213495 0.04941775 0.02497426 0.03220553 0.13901245\n",
            " 0.08999238 0.08880639]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load data\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train model\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = regressor.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Feature Importances:\", regressor.feature_importances_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca76e17",
      "metadata": {
        "id": "0ca76e17"
      },
      "source": [
        "## **Question 9:**\n",
        "Write a Python program to: \\\n",
        "● Load the Iris Dataset \\\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV \\\n",
        "● Print the best parameters and the resulting model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfaaeb11",
      "metadata": {
        "id": "bfaaeb11"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, None],\n",
        "    'min_samples_split': [2, 3, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb81ca4",
      "metadata": {
        "id": "7eb81ca4"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **Question 10:**  \n",
        "Imagine you’re working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values.\n",
        "\n",
        "### **Answer:**\n",
        "\n",
        "**Step-by-step process:**\n",
        "\n",
        "1. **Handle Missing Values**\n",
        "   - Use `SimpleImputer` to fill missing numeric values (mean/median).\n",
        "   - Fill missing categorical values with the most frequent category.\n",
        "\n",
        "2. **Encode Categorical Features**\n",
        "   - Use `LabelEncoder` for ordinal features.\n",
        "   - Use `OneHotEncoder` for nominal features to avoid introducing order bias.\n",
        "\n",
        "3. **Train a Decision Tree Model**\n",
        "   - Split the data into training and testing sets.\n",
        "   - Train `DecisionTreeClassifier(criterion='gini')`.\n",
        "\n",
        "4. **Tune Hyperparameters**\n",
        "   - Use `GridSearchCV` to tune `max_depth`, `min_samples_split`, and `criterion`.\n",
        "   - Select the model with the best cross-validation score.\n",
        "\n",
        "5. **Evaluate Model Performance**\n",
        "   - Use accuracy, precision, recall, F1-score, and confusion matrix.\n",
        "   - Evaluate on unseen test data to check generalization.\n",
        "\n",
        "**Business Value:**\n",
        "- Enables **early disease detection**, improving patient outcomes.\n",
        "- Helps **prioritize patients** for further tests.\n",
        "- Assists doctors in **decision support systems**.\n",
        "- Reduces healthcare costs through **predictive analytics** and efficient resource allocation."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}